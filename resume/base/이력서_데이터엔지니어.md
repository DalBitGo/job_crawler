# 박준현 | Data Engineer

> **Email**: junhyun1202@gmail.com
> **GitHub**: https://github.com/Dalbitgo
> **Phone**: 010-2215-6996

---

## Summary

**3년차 플랫폼/데이터 엔지니어**로, Airflow 기반 대규모 데이터 파이프라인 운영과 80개 이상의 Python 자동화 서비스 개발 경험을 보유하고 있습니다. 22개 고객사의 ETL 파이프라인을 설계/운영하며 데이터 품질 관리 시스템을 직접 구축했습니다.

**핵심 역량:**
- Airflow 기반 대규모 파이프라인 운영 (22개 고객사 DAG)
- 데이터 파이프라인 아키텍처 설계 및 최적화 (성능 60% 개선)
- 클라우드 데이터 플랫폼 구축/운영 (GCP)
- Python 기반 자동화 시스템 개발 (80+ 서비스)

---

## Technical Skills

| 분류 | 기술 |
|------|------|
| **Languages** | Python (주력), SQL, Shell Script |
| **Data Pipeline** | Apache Airflow, ETL/ELT |
| **Cloud (GCP)** | Cloud Run, Cloud Composer, BigQuery, Cloud Functions, GCS, Pub/Sub |
| **Database** | BigQuery, PostgreSQL, Firestore |
| **Infrastructure** | Docker, Cloud Build, IAM |
| **Monitoring** | Cloud Logging, Grafana, Custom Monitoring Tools |
| **API** | Flask, FastAPI, REST API |
| **학습 중** | Apache Kafka, Apache Spark |

---

## Work Experience

### 하이퍼라운지 (現 유클릭 합병) | 플랫폼 엔지니어 / 데이터 파이프라인 총괄
**2023.04 ~ 현재** | 서울

> 파견 입사 → 정식 전환 → 합병 (동일 업무 연속)
> 구조조정(70명→15명) 중 Tech팀 단독 운영, 전체 시스템 안정화 담당

#### 데이터 파이프라인 아키텍처 설계 및 운영

**Airflow 기반 대규모 파이프라인 운영**
- **22개 고객사**의 데이터 파이프라인을 Apache Airflow로 설계/운영
- DAG 의존성 관리, 스케줄링 최적화, 백필(Backfill) 처리
- 일일 **수백만 건** 데이터 처리

**Unified Converter 아키텍처 개선**
- 3개의 분산된 Cloud Function → 1개 Cloud Run으로 통합
- **성능 60% 개선**, API 호출 67% 감소, 장애 포인트 67% 감소
- Airflow Task 수 75% 감소 (6-8개 → 2-3개)

**E2E 데이터 플로우 설계**
```
Crawler → FileID Mapping → Filter → Convert → Tag → Tag-Prep → Load → Transform → Sync
```

#### 모니터링 시스템 구축

- **4개의 자체 모니터링 시스템** 설계 및 개발
  - `airflow_dag_monitor`: DAG 실행 상태 실시간 추적
  - `history_checker`: 파이프라인 이력 관리
  - `converter_failure_monitor`: 변환 실패 즉시 알림
  - `sli_slo`: 서비스 수준 지표 관리
- 장애 대응 시간 **50% 단축**

#### 클라우드 인프라 운영 (GCP)

- Cloud Run 기반 서비스 배포 및 자동 스케일링
- Cloud Composer (Managed Airflow) 환경 운영
- BigQuery 데이터 웨어하우스 설계 및 최적화
- Cloud Build CI/CD 파이프라인 구축

#### Python 자동화 서비스 개발

- **80개 이상**의 마이크로서비스 설계/개발/운영
- 데이터 수집, 변환, 태깅, 동기화 등 전체 스택 담당
- 일일 수작업 **6시간 절감** 효과

### 이전 경력 (RPA 개발)
**2020.11 ~ 2023.03** | 커머스랩, 코어플러스

- UiPath/AntBot 기반 RPA 봇 개발 및 업무 자동화
- 메타 데이터 작성 및 모니터링
- RPA 경험을 바탕으로 데이터 엔지니어로 직무 전환

---

## Projects

### realtime-crypto-pipeline (개인 프로젝트)
**2026.01 ~ 진행 중** | [GitHub Link]

실시간 암호화폐 거래 데이터 수집 → 처리 → 분석 파이프라인

**기술 스택:** Python, Apache Kafka, Apache Spark (학습 중), PostgreSQL, Docker

**주요 구현:**
- Binance WebSocket API 실시간 데이터 수집 (5개 심볼)
- Kafka Producer 구현 (aiokafka, 배치 최적화)
- Airflow DAG 기반 데이터 품질 관리
- Grafana 실시간 대시보드

**목표:**
- 처리량: 10,000 msg/sec
- 지연: < 100ms

### 이메일 첨부파일 수집 시스템 (email-collector-v2)
**2026.01** | 사내 프로젝트

SendGrid Inbound Parse 기반 프로덕션 수준 이메일 처리 시스템

**주요 구현:**
- 안정성 패턴: 지수 백오프 + 지터, 서킷 브레이커, Dead Letter Queue
- 멱등성 보장 (메시지 ID + 첨부파일 해시)
- 발신자 검증 (SPF/DKIM/DMARC), GDPR 감사 추적
- 엣지 케이스 처리: winmail.dat 파싱, 유니코드 파일명, 중첩 이메일

---

## Key Achievements

| 성과 | 상세 | 임팩트 |
|------|------|--------|
| **파이프라인 통합** | 3개 서비스 → 1개 통합 | 성능 60%↑, 유지보수 비용↓ |
| **대규모 운영** | 22개 고객사 DAG | 일일 수백만 건 처리 |
| **자동화** | 80+ Python 서비스 | 일일 6시간 절감 |
| **모니터링** | 4개 시스템 구축 | 장애 대응 50% 단축 |

---

## Education

### 한양대학교 | 경영학부
**2011.03 ~ 2018.08**

---

## Certifications

- 네트워크관리사 2급 (2024)
- 무역영어 1급 (2018)

---

## Why Me?

### 1. Airflow 실전 경험
단순 사용이 아닌, **22개 고객사 규모**의 복잡한 DAG를 설계하고 운영한 경험이 있습니다. 의존성 관리, 백필 처리, 모니터링까지 전체 사이클을 경험했습니다.

### 2. 데이터 파이프라인 아키텍처
분산된 시스템을 통합하여 **성능 60% 개선**한 경험이 있습니다. 단순 개발이 아닌 아키텍처 관점에서 시스템을 바라봅니다.

### 3. 문제 해결 능력
4개의 모니터링 시스템을 직접 설계/개발하여 **장애 대응 시간을 50% 단축**했습니다. 문제를 발견하고 시스템으로 해결합니다.

### 4. 빠른 학습 능력
현재 Kafka + Spark를 개인 프로젝트로 학습 중입니다. 새로운 기술도 빠르게 습득하여 적용할 수 있습니다.

---

*마지막 업데이트: 2026-01-24*
