# 박준현 | 데이터 엔지니어 지원 (당근페이)

---

## 지원 포지션과 매칭되는 핵심 경험

### 당근페이 요구사항 → 내 경험

| 당근페이 요구 | 내 경험 | 상세 |
|-------------|--------|------|
| **Airflow 워크플로우 관리** | ✅ 22개 고객사 DAG | 대규모 파이프라인 운영 |
| **클라우드 데이터 플랫폼** | ✅ GCP 전반 운영 | Cloud Run, BigQuery, Composer |
| **대용량 데이터 처리 3년+** | ✅ 3년차 | 일일 수백만 건 처리 |
| **Kafka (우대)** | △ 학습 중 | 개인 프로젝트 Producer 완료 |

---

## 핵심 경력 요약

### 하이퍼라운지 | 플랫폼 엔지니어 (3년)

**1. Airflow 워크플로우 전문성**
```
• 22개 고객사 DAG 설계/운영
• 복잡한 의존성 관리 및 스케줄링
• 백필 처리 및 실패 복구 자동화
• DAG 모니터링 시스템 직접 개발
```

**2. 클라우드 데이터 플랫폼 운영**
```
• GCP 서비스 전반 운영 경험
  - Cloud Run: 서비스 배포 및 오토스케일링
  - Cloud Composer: Managed Airflow 환경
  - BigQuery: 데이터 웨어하우스 설계/최적화
  - Cloud Functions, GCS, Pub/Sub
```

**3. E2E 파이프라인 설계**
```
Crawler → Filter → Convert → Tag → Load → Transform → Sync

• 전체 데이터 플로우 설계 및 구현
• 80+ 마이크로서비스로 구성
• 일일 수백만 건 안정적 처리
```

---

## 당근페이에서 기여할 수 있는 점

### 1. Airflow 실전 경험
당근페이 요구사항인 "Airflow 워크플로우 관리 경험"에 정확히 부합합니다. 단순 사용이 아닌 **22개 고객사 규모**의 복잡한 파이프라인을 설계하고 운영했습니다.

### 2. 클라우드 전환 용이
GCP에서 운영한 경험이 풍부하며, 클라우드 개념은 AWS와 동일하므로 **빠른 전환이 가능**합니다.
- GCS → S3
- Cloud Run → ECS/Lambda
- BigQuery → Redshift/Athena
- Pub/Sub → Kinesis/SQS

### 3. Kafka 역량 확보 중
현재 개인 프로젝트에서 **Kafka Producer를 구현 완료**했습니다. 입사 전까지 Consumer와 Spark Streaming 연동까지 완료할 예정입니다.

---

## 기술 스택

```
주력:    Python, SQL, Airflow, GCP (Cloud Run, BigQuery, Composer)
사용:    Docker, PostgreSQL, Flask/FastAPI, Grafana
학습중:  Kafka (Producer 완료), Spark Streaming (진행 중)
        AWS (GCP 경험 기반 전환 준비)
```

---

## 개인 프로젝트

### realtime-crypto-pipeline
**Kafka + Spark 학습 프로젝트**

- Binance 실시간 데이터 수집
- Kafka Producer 구현 완료 (aiokafka)
- Spark Streaming Consumer 진행 중
- 목표: 10,000 msg/sec 처리

---

## 연락처

- **Email**: [이메일]
- **GitHub**: [GitHub URL]
- **Phone**: [전화번호]

---

*Airflow와 클라우드 경험을 바탕으로 당근페이의 데이터 플랫폼에 기여하고 싶습니다.*
