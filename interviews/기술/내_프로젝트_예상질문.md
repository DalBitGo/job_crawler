# 내 프로젝트 기반 예상 질문

> **목적**: 이력서에 쓴 내용 기반 면접 대비
> **원칙**: 모든 질문에 "왜?"와 "어떻게?"를 답할 수 있어야 함

---

## 1. unified-converter (아키텍처 통합)

### 기본 질문

| 질문 | 답변 포인트 |
|------|------------|
| 이게 뭐예요? | 엑셀 파일을 파싱해서 정형화된 데이터로 변환하는 시스템 |
| 왜 통합했어요? | 3개 분산 → 장애 포인트 많음, API 호출 비효율 |
| 60% 개선 어떻게 측정? | 처리 시간 비교 (Before/After) |

### 심화 질문

**Q: "3개를 1개로 통합한 과정 설명해주세요"**

```
Before:
┌─────────┐    ┌─────────┐    ┌─────────┐
│ CF1     │ →  │ CF2     │ →  │ CF3     │
│ (파싱)  │    │ (변환)  │    │ (저장)  │
└─────────┘    └─────────┘    └─────────┘
- 각각 API 호출 필요
- 중간 데이터 GCS에 저장
- 장애 포인트 3개

After:
┌─────────────────────────────────────┐
│          Cloud Run (통합)           │
│  파싱 → 변환 → 저장 (한 번에)        │
└─────────────────────────────────────┘
- API 호출 1번
- 중간 저장 없음
- 장애 포인트 1개
```

**Q: "성능 60% 개선 근거가 뭐예요?"**

```
측정 방법:
1. 동일한 파일로 Before/After 처리 시간 측정
2. Cloud Logging에서 시작/종료 시간 추출
3. 평균 처리 시간 비교

결과:
- Before: 평균 5분
- After: 평균 2분
- 개선율: (5-2)/5 = 60%

추가 개선:
- API 호출 67% 감소 (3번 → 1번)
- Airflow Task 75% 감소 (6-8개 → 2-3개)
```

**Q: "어려웠던 점은?"**

```
1. 레거시 코드 이해
   - 문서 없음, 원 개발자 퇴사
   - 코드 분석으로 로직 파악

2. 점진적 마이그레이션
   - 한 번에 전환 불가 (22개 고객사)
   - 고객사별 순차 적용

3. 롤백 계획
   - 문제 시 기존 시스템으로 복귀 가능하게
```

---

## 2. airflow_dag_monitor (모니터링 시스템)

### 기본 질문

| 질문 | 답변 포인트 |
|------|------------|
| 왜 직접 만들었어요? | 기존 도구로 부족한 부분 있어서 |
| 어떤 지표 수집해요? | DAG 실행 상태, 실패율, 소요시간 |
| 50% 단축 어떻게? | 즉시 알림 + 한눈에 현황 파악 |

### 심화 질문

**Q: "모니터링 시스템 구조 설명해주세요"**

```
┌─────────────────────────────────────────────────┐
│                 Cloud Composer                   │
│                                                  │
│   DAG 실행 → 메타데이터 DB (PostgreSQL)          │
└───────────────────┬─────────────────────────────┘
                    │
                    ▼
┌─────────────────────────────────────────────────┐
│            airflow_dag_monitor                   │
│                                                  │
│   1. Airflow API로 DAG 상태 조회                 │
│   2. 실패/지연 감지                              │
│   3. Slack 알림                                  │
│   4. 대시보드 데이터 생성                        │
└─────────────────────────────────────────────────┘
```

**Q: "어떤 알림을 보내요?"**

```python
# 1. 즉시 알림 (실패)
- DAG 실패 시
- Task 실패 시 (retry 소진 후)

# 2. 경고 알림 (지연)
- SLA 초과 시
- 평소보다 2배 이상 소요 시

# 3. 요약 알림 (일간)
- 일간 실행 현황
- 실패율 추이
```

**Q: "장애 대응 시간 50% 단축 근거?"**

```
Before (모니터링 없음):
- 장애 인지: 고객사 문의 또는 다음 날 확인
- 평균 인지 시간: 2-4시간

After (모니터링 적용):
- 장애 인지: Slack 즉시 알림
- 평균 인지 시간: 5-10분

실제로는 50% 이상이지만, 보수적으로 50%로 표현
```

---

## 3. email-collector-v2 (안정성 패턴)

### 기본 질문

| 질문 | 답변 포인트 |
|------|------------|
| 이게 뭐예요? | 이메일 첨부파일 자동 수집 시스템 |
| 왜 v2예요? | v1의 안정성 문제 해결 |
| 안정성 패턴이란? | retry, circuit breaker, DLQ |

### 심화 질문

**Q: "지수 백오프 + 지터 설명해주세요"**

```python
# 지수 백오프 (Exponential Backoff)
# 재시도 간격: 1초 → 2초 → 4초 → 8초

# 문제: 여러 클라이언트가 같은 시간에 재시도 (Thundering Herd)

# 지터 (Jitter) 추가
# 재시도 간격에 랜덤 값 추가
# 1초 + random(0, 1초) = 1.3초
# 2초 + random(0, 2초) = 2.7초

# 효과: 재시도 시점 분산 → 서버 부하 방지

import random

def get_retry_delay(attempt: int, base: float = 1.0) -> float:
    exp_delay = base * (2 ** attempt)
    jitter = random.uniform(0, exp_delay)
    return exp_delay + jitter
```

**Q: "서킷 브레이커 설명해주세요"**

```
상태 전이:
CLOSED (정상) → OPEN (차단) → HALF_OPEN (테스트)

┌──────────┐  실패 임계값 초과  ┌──────────┐
│  CLOSED  │ ─────────────────→ │   OPEN   │
│ (정상)   │                    │ (차단)   │
└──────────┘                    └────┬─────┘
     ↑                               │
     │           타임아웃 후         │
     │       ┌───────────────────────┘
     │       ↓
     │  ┌──────────┐
     └──│HALF_OPEN │ 성공 시 CLOSED로
        │ (테스트) │ 실패 시 OPEN으로
        └──────────┘

효과: 장애 전파 방지, 빠른 실패
```

**Q: "DLQ(Dead Letter Queue) 어떻게 사용했어요?"**

```
정상 흐름:
메일 수신 → 처리 → 완료

실패 흐름:
메일 수신 → 처리 실패 → 재시도 (3회)
    → 계속 실패 → DLQ로 이동

DLQ 처리:
- 나중에 수동 확인
- 원인 분석 후 재처리
- 데이터 유실 방지
```

**Q: "멱등성(Idempotency) 어떻게 보장?"**

```python
# 같은 메일을 여러 번 처리해도 결과가 같아야 함

# 방법: 메시지 ID + 첨부파일 해시로 중복 체크

def process_email(email):
    # 1. 고유 키 생성
    unique_key = f"{email.message_id}_{hash(attachment)}"

    # 2. 이미 처리했는지 확인
    if already_processed(unique_key):
        return  # 스킵

    # 3. 처리
    result = do_process(email)

    # 4. 처리 완료 기록
    mark_processed(unique_key)

    return result
```

---

## 4. TCP Idle Timeout 이슈

### 기본 질문

| 질문 | 답변 포인트 |
|------|------------|
| 무슨 문제였어요? | 10분 이상 걸리는 작업이 응답 못 받음 |
| 원인이 뭐였어요? | GKE Node의 TCP idle timeout 600초 |
| 어떻게 해결했어요? | TCP Keepalive 활성화 |

### 심화 질문

**Q: "문제 발견 과정 설명해주세요"**

```
1. 증상 발견
   - Cloud Run은 200 OK (성공)
   - Airflow는 응답 못 받고 timeout

2. 패턴 분석
   - 595초: 성공
   - 607초: 실패
   → 600초 경계에서 갈림

3. 원인 파악
   - Google 문서 확인
   - "TCP idle connections are disconnected after 600 seconds"

4. 해결
   - TCP Keepalive 적용 (60초마다 신호)
```

**Q: "TCP Keepalive 코드 설명해주세요"**

```python
import socket
from requests.adapters import HTTPAdapter

class TCPKeepAliveAdapter(HTTPAdapter):
    def init_poolmanager(self, *args, **kwargs):
        kwargs['socket_options'] = [
            # keepalive 활성화
            (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
            # 60초 후 시작
            (socket.IPPROTO_TCP, socket.TCP_KEEPIDLE, 60),
            # 60초 간격
            (socket.IPPROTO_TCP, socket.TCP_KEEPINTVL, 60),
            # 10회 시도
            (socket.IPPROTO_TCP, socket.TCP_KEEPCNT, 10),
        ]
        super().init_poolmanager(*args, **kwargs)

# TCP_KEEPIDLE=60: 60초 동안 데이터 없으면 keepalive 시작
# TCP_KEEPINTVL=60: 60초마다 keepalive 패킷 전송
# TCP_KEEPCNT=10: 10번 응답 없으면 연결 끊김으로 판단
```

---

## 5. 22개 고객사 DAG 운영

### 기본 질문

| 질문 | 답변 포인트 |
|------|------------|
| 왜 22개나? | 고객사별 다른 데이터 소스, 스케줄 |
| 어떻게 관리해요? | 동적 DAG 생성, 공통 템플릿 |
| 한 곳 실패하면? | 다른 고객사 영향 없음 (격리) |

### 심화 질문

**Q: "동적 DAG 생성 어떻게 해요?"**

```python
# 1. 설정 파일에서 고객사 정보 로드
CUSTOMERS = load_config('customers.yaml')
# [{'id': 'c001', 'schedule': '0 9 * * *'}, ...]

# 2. 고객사별 DAG 생성
def create_customer_dag(customer):
    dag_id = f"etl_{customer['id']}"

    with DAG(
        dag_id=dag_id,
        schedule_interval=customer['schedule'],
        catchup=False,
    ) as dag:
        # 공통 로직, 고객별 설정만 다름
        extract = create_extract_task(customer)
        transform = create_transform_task(customer)
        load = create_load_task(customer)

        extract >> transform >> load

    return dag

# 3. 전역 변수로 등록 (Airflow가 인식하도록)
for customer in CUSTOMERS:
    dag = create_customer_dag(customer)
    globals()[dag.dag_id] = dag
```

**Q: "고객사별 격리 어떻게?"**

```
1. 별도 DAG
   - 한 고객 DAG 실패해도 다른 DAG는 정상 실행

2. 별도 설정
   - 고객별 API 키, 경로 등 분리

3. 별도 알림
   - 실패 시 해당 고객 담당자에게만 알림

4. 백필도 독립적
   - 특정 고객만 재처리 가능
```

---

## 6. 구조조정 상황 (70명 → 15명)

### 예상 질문

**Q: "팀원 다 나가고 혼자 남았는데 어떻게 했어요?"**

```
1. 우선순위 설정
   - 핵심 시스템만 유지
   - 비핵심 기능 중단 또는 간소화

2. 자동화 강화
   - 모니터링 시스템으로 장애 빠르게 감지
   - 반복 작업 스크립트화

3. 문서화
   - 혼자 아는 것 문서로 정리
   - 나중에 인수인계 대비

4. 심적 준비
   - 모든 것 완벽하게 못함 인정
   - 핵심만 확실하게
```

**Q: "왜 남았어요?"**

```
솔직하게:
- 책임감 (시스템이 멈추면 고객 영향)
- 이 경험이 성장에 도움될 것이라 생각

어필 포인트:
- 어려운 상황에서도 시스템 유지
- 혼자서 전체 시스템 파악/운영 가능
- 위기 관리 능력
```

---

## 면접 전 체크리스트

### 각 프로젝트별 준비

- [ ] unified-converter: 통합 전후 비교, 60% 개선 근거
- [ ] airflow_dag_monitor: 아키텍처, 알림 종류, 50% 단축 근거
- [ ] email-collector-v2: 안정성 패턴 3개 (retry, CB, DLQ) 설명
- [ ] TCP Idle Timeout: 문제 발견 과정, Keepalive 코드 설명
- [ ] 22개 DAG: 동적 생성 방식, 격리 방법

### 공통 준비

- [ ] 모든 숫자에 근거 (60%, 50%, 22개 등)
- [ ] "왜?" 질문에 답변
- [ ] 코드 없이도 설명 가능하게

---

*마지막 업데이트: 2026-02-13*
