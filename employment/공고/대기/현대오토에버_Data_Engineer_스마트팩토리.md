# 현대오토에버 - [SDx] Data Engineer (스마트팩토리)

> **상태**: 관심
> **발견일**: 2026-01-24
> **마감일**: 채용시 마감
> **지원일**: -
> **출처**: career.hyundai-autoever.com
> **매칭도**: ★★★★★ (최우선 지원 대상)

---

## 1. 공고 정보

### 1.1 회사 정보
| 항목 | 내용 |
|------|------|
| 회사명 | 현대오토에버 |
| 사업 분야 | 스마트팩토리, 모빌리티 SW |
| 위치 | 서울특별시 강남구 대치동 |
| 규모 | 대기업 (현대자동차그룹) |

### 1.2 포지션 정보
| 항목 | 내용 |
|------|------|
| 포지션명 | [SDx] Data Engineer - 스마트팩토리 데이터 파이프라인 개발 및 운영 |
| 경력 요건 | 3년 이상 |
| 고용 형태 | 정규직 |
| 팀 | SDF데이터서비스팀 |

### 1.3 공고 링크
```
https://career.hyundai-autoever.com/ko/o/186743
```

---

## 2. 담당업무

- 스마트팩토리 전반의 데이터 파이프라인 개발 및 운영
- **Airflow를 활용한 파이프라인 자동화** ⭐ 직접 매칭
- 비즈니스 요구사항에 따른 데이터 정제 및 클렌징
- 신뢰성 있고 확장 가능한 데이터 서비스 설계 및 개발
- 데이터 시각화 분석 서비스 제공

---

## 3. 요구사항 분석

### 3.1 필수 요건 (Requirements)
| 요건 | 내 수준 | 매칭 | 증빙 |
|------|---------|------|------|
| Hadoop 에코시스템 이해 | ★★☆☆☆ | Gap | realtime-crypto-pipeline으로 학습 중 |
| Hadoop, Hive, Spark 경험 | ★★☆☆☆ | Gap | Phase 3에서 Spark 학습 예정 |
| 대용량 데이터 처리 아키텍처 | ★★★★☆ | **충분** | BigQuery + Airflow 22개 고객사 |
| 데이터 마트/DW + SQL/NoSQL | ★★★★★ | **충분** | BigQuery, PostgreSQL 실무 |
| Java/Scala/Python 능숙 | ★★★★★ | **충분** | Python 메인, 80+ 서비스 개발 |

### 3.2 우대 요건 (Nice to have)
| 요건 | 내 수준 | 매칭 | 증빙 |
|------|---------|------|------|
| PL로 프로젝트 주도 경험 | ★★★★☆ | **충분** | Unified Converter 프로젝트 리드 |
| 제조 설비/장비 데이터 수집 | ★★☆☆☆ | 유사 | RPA로 Board 데이터 수집 (유사) |
| 온프레미스/클라우드 플랫폼 경험 | ★★★★★ | **충분** | GCP 전반 운영 |
| DevOps CI/CD 경험 | ★★★☆☆ | 보통 | Cloud Build 사용 |

### 3.3 기술 스택 매칭
```
공고 요구:       [Hadoop] [Hive] [Spark] [Airflow] [Python] [SQL]
내가 가진 것:    [Airflow✅] [Python✅] [SQL✅] [BigQuery✅] [GCP✅]
Gap:            [Hadoop] [Hive] [Spark]
```

---

## 4. 내 강점 매칭 (어필 포인트)

### 4.1 직접 매칭되는 경험
| 공고 요구 | 내 경험 | 면접 답변 |
|---------|--------|----------|
| Airflow 파이프라인 자동화 | 22개 고객사 DAG 운영 | "22개 고객사의 데이터 파이프라인을 Airflow로 운영하며 DAG 모니터링 시스템을 직접 개발했습니다" |
| 대용량 데이터 처리 | BigQuery + ETL | "일일 수백만 건의 데이터를 BigQuery로 처리하고 PostgreSQL과 동기화하는 시스템을 설계했습니다" |
| 데이터 정제/클렌징 | Unified Converter | "3개의 Cloud Function을 1개의 Cloud Run으로 통합하여 성능 60% 개선, 장애 포인트 67% 감소" |
| 신뢰성/확장성 서비스 | 파이프라인 아키텍처 | "Crawler → Filter → Convert → Tag → Load → Sync 전체 플로우를 설계하고 운영 중" |

### 4.2 유사한 경험
| 공고 요구 | 내 유사 경험 | 연결 논리 |
|---------|-------------|----------|
| 제조 데이터 수집 | RPA Board 수집 | "RPA로 다양한 소스에서 데이터 수집 경험 → 제조 설비 데이터 수집도 빠르게 적응 가능" |
| Spark 경험 | realtime-crypto-pipeline | "현재 Kafka + Spark 프로젝트 진행 중으로 빠른 시일 내 역량 확보 예정" |

### 4.3 Gap 대응 전략
| Gap | 보완 방법 | 현재 상태 |
|-----|----------|----------|
| Hadoop/Spark | realtime-crypto-pipeline Phase 3 | Kafka 완료, Spark 진행 예정 |
| 제조 도메인 | 면접 전 제조 데이터 특성 학습 | 예정 |

---

## 5. 지원 준비

### 5.1 자기소개서 핵심 포인트
```
1. Airflow 22개 고객사 DAG 운영 - 대규모 파이프라인 관리 경험
2. Unified Converter - 아키텍처 개선으로 60% 성능 향상
3. 80+ 마이크로서비스 - 데이터 플랫폼 전체 설계/운영
4. realtime-crypto-pipeline - Spark 학습 의지 + 진행 중인 프로젝트
```

### 5.2 면접 예상 질문
- [ ] "Airflow 운영 경험 설명해주세요" → 22개 DAG + 모니터링 시스템
- [ ] "대용량 데이터 처리 경험?" → BigQuery + ETL 파이프라인
- [ ] "Spark 경험이 부족한데?" → 개인 프로젝트로 학습 중 + 빠른 적응력
- [ ] "데이터 품질 관리 방법?" → history_checker + failure_monitor

### 5.3 체크리스트
- [ ] realtime-crypto-pipeline Phase 3 (Spark) 진행
- [ ] 이력서 Airflow/파이프라인 강조
- [ ] 포트폴리오 README 정리
- [ ] 제조 데이터 특성 학습
- [ ] 지원서 작성

---

## 6. 진행 기록

| 날짜 | 단계 | 내용 |
|------|------|------|
| 2026-01-24 | 공고 발견 | 스마트팩토리 Data Engineer |
| 2026-01-24 | 요구사항 분석 | 매칭도 ★★★★★ - 최우선 지원 |

---

## 7. 총평

### 매칭도: ★★★★★ (5/5)

**이 포지션이 최적인 이유:**
1. **Airflow 직접 경험** - 22개 고객사 DAG 운영은 드문 경험
2. **데이터 파이프라인 설계** - 전체 플로우 설계 경험
3. **Python + SQL** - 메인 스택 완벽 일치
4. **대용량 처리** - BigQuery 실무 경험

**보완 필요:**
- Spark 경험 → 개인 프로젝트로 보완 중

> **결론**: 적극 지원 대상. Spark 학습 병행하며 빠른 지원 권장.

---

*파일 이동: 지원 시 `지원완료/`로 이동*
