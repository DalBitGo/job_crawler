# 현대오토에버 - [Tech] Solution Developer (자동화 서비스 DevOps)

> **상태**: 관심
> **발견일**: 2026-01-24
> **마감일**: 채용시 마감
> **지원일**: -
> **출처**: LinkedIn
> **매칭도**: ★★★★☆ (적극 지원 대상)

---

## 1. 공고 정보

### 1.1 회사 정보
| 항목 | 내용 |
|------|------|
| 회사명 | 현대오토에버 |
| 사업 분야 | 자동화 서비스, 인프라 |
| 위치 | 서울/경기 |
| 규모 | 대기업 (현대자동차그룹) |

### 1.2 포지션 정보
| 항목 | 내용 |
|------|------|
| 포지션명 | [Tech] Solution Developer - 자동화 서비스 DevOps |
| 경력 요건 | 경력 (상세 확인 필요) |
| 고용 형태 | 정규직 |
| Job ID | 4362651415 (LinkedIn) |

### 1.3 공고 링크
```
https://career.hyundai-autoever.com/ko/apply
LinkedIn Job ID: 4362651415
```

---

## 2. 담당업무 (추정)

- 인프라 자동화 도구 개발
- CI/CD 파이프라인 구축 및 운영
- 시스템 모니터링 및 장애 분석
- 자동화 스크립트 개발 (Python, Shell)

---

## 3. 요구사항 분석

### 3.1 필수 요건 (Requirements)
| 요건 | 내 수준 | 매칭 | 증빙 |
|------|---------|------|------|
| Python, Shell Script | ★★★★★ | **충분** | 80+ 서비스 Python 개발 |
| IT 인프라 이해 (네트워크, OS) | ★★★☆☆ | 보통 | GCP 인프라 운영 |
| 시스템 모니터링/장애 분석 | ★★★★★ | **충분** | 모니터링 시스템 4개 직접 개발 |
| CI/CD 파이프라인 구축 | ★★★☆☆ | 보통 | Cloud Build 사용 경험 |

### 3.2 우대 요건 (Nice to have)
| 요건 | 내 수준 | 매칭 | 증빙 |
|------|---------|------|------|
| Kafka 핵심 개념 이해 | ★★★☆☆ | 보통 | realtime-crypto-pipeline으로 학습 중 |
| 데이터 시각화 대시보드 경험 | ★★★★☆ | **충분** | Grafana 대시보드 구축 |
| Ansible | ★☆☆☆☆ | Gap | 미경험 |
| Kubernetes | ★★☆☆☆ | Gap | Phase 4에서 학습 예정 |
| Docker | ★★★★☆ | **충분** | Docker Compose 멀티 컨테이너 |

### 3.3 기술 스택 매칭
```
공고 요구:       [Python] [Shell] [Docker] [K8s] [Ansible] [Kafka] [CI/CD]
내가 가진 것:    [Python✅] [Shell✅] [Docker✅] [Airflow✅] [GCP✅]
Gap:            [Kubernetes] [Ansible]
학습 중:         [Kafka - Phase 3]
```

---

## 4. 내 강점 매칭

### 4.1 직접 매칭되는 경험
| 공고 요구 | 내 경험 | 면접 답변 |
|---------|--------|----------|
| Python 자동화 | 80+ 마이크로서비스 | "80개 업무 자동화 서비스를 Python으로 개발/운영 중" |
| 모니터링/장애 분석 | 4개 모니터링 시스템 | "history_checker, dag_monitor 등 자체 모니터링 시스템 개발" |
| 데이터 시각화 | Grafana | "파이프라인 상태 실시간 대시보드 구축, 장애 대응 시간 단축" |
| CI/CD | Cloud Build | "Cloud Run 자동 배포 파이프라인 구축" |

### 4.2 유사한 경험
| 공고 요구 | 내 유사 경험 | 연결 논리 |
|---------|-------------|----------|
| Kafka | realtime-crypto-pipeline | "현재 Kafka Producer 구현 완료, 실시간 파이프라인 구축 중" |
| Kubernetes | Docker Compose | "멀티 컨테이너 운영 경험 → K8s 빠른 적응 가능" |

### 4.3 Gap 대응 전략
| Gap | 보완 방법 | 현재 상태 |
|-----|----------|----------|
| Kubernetes | realtime-crypto-pipeline Phase 4 | 계획됨 |
| Ansible | 개인 학습 필요 | 미시작 |

---

## 5. 지원 준비

### 5.1 자기소개서 핵심 포인트
```
1. 자동화 전문성 - 80+ Python 자동화 서비스 개발/운영
2. 모니터링 시스템 - 4개 모니터링 툴 직접 개발
3. 파이프라인 경험 - Airflow 22개 DAG 운영
4. 학습 의지 - Kafka + Spark 개인 프로젝트 진행 중
```

### 5.2 면접 예상 질문
- [ ] "자동화 경험 설명해주세요" → 80+ 서비스 + Unified Converter
- [ ] "모니터링 시스템 구축 경험?" → 4개 시스템 상세 설명
- [ ] "Kubernetes 경험?" → Docker 경험 + 학습 계획
- [ ] "장애 대응 사례?" → converter_failure_monitor + 알림

### 5.3 체크리스트
- [ ] 공고 상세 내용 재확인
- [ ] 이력서 자동화/DevOps 강조
- [ ] Kubernetes 기초 학습
- [ ] 지원서 작성

---

## 6. 진행 기록

| 날짜 | 단계 | 내용 |
|------|------|------|
| 2026-01-24 | 공고 발견 | LinkedIn에서 발견 |
| 2026-01-24 | 요구사항 분석 | 매칭도 ★★★★☆ |

---

## 7. 총평

### 매칭도: ★★★★☆ (4/5)

**강점:**
1. **Python 자동화** - 80+ 서비스는 강력한 어필 포인트
2. **모니터링** - 직접 개발 경험 차별화
3. **Docker** - 컨테이너 기반 운영 경험

**보완 필요:**
- Kubernetes, Ansible 경험 부족

> **결론**: Data Engineer보다 매칭도 낮지만, 자동화 경험으로 어필 가능. 병행 지원 권장.

---

*파일 이동: 지원 시 `지원완료/`로 이동*
