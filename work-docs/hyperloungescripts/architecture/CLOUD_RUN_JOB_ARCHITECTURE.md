# Cloud Run Job í¬ë¡¤ëŸ¬ ì•„í‚¤í…ì²˜ ê°€ì´ë“œ

## ëª©ì°¨
- [ê°œìš”](#ê°œìš”)
- [ì „ì²´ ì‹¤í–‰ íë¦„](#ì „ì²´-ì‹¤í–‰-íë¦„)
- [ë³‘ë ¬ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜](#ë³‘ë ¬-ì²˜ë¦¬-ë©”ì»¤ë‹ˆì¦˜)
- [ë©”ëª¨ë¦¬ ê´€ë¦¬ ì›ë¦¬](#ë©”ëª¨ë¦¬-ê´€ë¦¬-ì›ë¦¬)
- [ì‹¤í–‰ íë¦„ ë¹„êµ](#ì‹¤í–‰-íë¦„-ë¹„êµ)
- [í•µì‹¬ ì •ë¦¬](#í•µì‹¬-ì •ë¦¬)

---

## ê°œìš”

Hyperlounge ìˆ˜ì§‘ ì‹œìŠ¤í…œì—ì„œ Board í¬ë¡¤ëŸ¬ëŠ” Cloud Run Jobì„ í†µí•´ ì‹¤í–‰ë©ë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” Airflow DAGì—ì„œ Cloud Run Jobì´ ì‹¤í–‰ë˜ê³ , ë³‘ë ¬ ì²˜ë¦¬ê°€ ì´ë£¨ì–´ì§€ëŠ” ì „ì²´ ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- **í™•ì¥ì„±**: í•„ìš”ì— ë”°ë¼ ìˆ˜ë°± ê°œì˜ ë³‘ë ¬ ì‘ì—… ê°€ëŠ¥
- **ê²©ë¦¬ì„±**: ê° ì‘ì—…ì´ ë…ë¦½ëœ ì»¨í…Œì´ë„ˆì—ì„œ ì‹¤í–‰
- **íš¨ìœ¨ì„±**: ì‘ì—… ë¶„ë°°ë¥¼ í†µí•œ ë¹ ë¥¸ ì²˜ë¦¬
- **ì•ˆì •ì„±**: í•œ ì‘ì—… ì‹¤íŒ¨ê°€ ë‹¤ë¥¸ ì‘ì—…ì— ì˜í–¥ ì—†ìŒ

---

## ì „ì²´ ì‹¤í–‰ íë¦„

### 1ï¸âƒ£ Airflow DAGì—ì„œ ì‹œì‘

**íŒŒì¼**: `airflow-dags/dags/c230c700.py:134-137`

```python
# board sourceê°€ í™œì„±í™”ë˜ë©´
crawler_task = TaskFactory.create_crawler_task(CONFIG, source, dag=dag)

# Task ì˜ì¡´ì„±
start_collect_task >> crawler_task >> fileid_mapping_task
```

**ì—­í• **: ì›ìµíì—”ì”¨ DAGì—ì„œ board í¬ë¡¤ë§ ì‘ì—… ì •ì˜

---

### 2ï¸âƒ£ TaskFactoryê°€ Airflow Task ìƒì„±

**íŒŒì¼**: `airflow-dags/dags/dependencies/task_factory.py:108-116`

```python
crawler_task = PythonOperator(
    task_id=f"crawler-{source_type}",
    python_callable=TaskFunctions.crawl_files,
    params={
        **dag_config,
        'source_type': source_type,
        'non_excel_crawl': non_excel_crawl
    }
)
```

**ì—­í• **: Python Operatorë¥¼ ìƒì„±í•˜ì—¬ `TaskFunctions.crawl_files` í•¨ìˆ˜ë¥¼ ì‹¤í–‰

---

### 3ï¸âƒ£ crawl_filesê°€ Cloud Run Job í˜¸ì¶œ

**íŒŒì¼**: `collector/cloud/file_crawler.py:122`

```python
if source_type == SOURCE_BOARD:
    crawl_actions = get_task_items(api_svr_url, customer_code, source_type,
                                   TASK_CRAWL, ingestion_id, source_id)

    if crawl_actions:
        board_crawler_with_job(customer_code, source_type, source_id, ingestion_id)
```

**ì—­í• **: Firestoreì—ì„œ í¬ë¡¤ ì•¡ì…˜ì„ ê°€ì ¸ì™€ Cloud Run Job ì‹¤í–‰

---

### 4ï¸âƒ£ Cloud Run Job ì‹¤í–‰ ì¤€ë¹„

**íŒŒì¼**: `collector/boards/main_board_crawler.py:214-256`

#### a) BSDA ë¦¬ìŠ¤íŠ¸ ìƒì„± ë° GCS ì—…ë¡œë“œ

```python
bsda = datetime.strptime(ingestion_id, "%Y%m%d%H%M%S").strftime("%Y-%m-%d")
ingestion_time = ingestion_id[8:]  # "230000"

bsda_list = [{"start": bsda, "end": bsda}]
# ì˜ˆ: [{"start": "2025-12-02", "end": "2025-12-02"}]

bsda_list_path = upload_bsda_list(
    bsda_list,
    bucket_name="hyperlounge-collect-config",
    customer_code="c230c700",
    source_type="board",
    source_id="s26fc26d",
    job_name="crawler"
)
# ê²°ê³¼: "crawler/c230c700/board/s26fc26d/20251203081500"
```

#### b) í™˜ê²½ë³€ìˆ˜ ì¤€ë¹„

```python
env_vars = [
    {"name": "customer_code", "value": "c230c700"},
    {"name": "source_type", "value": "board"},
    {"name": "source_id", "value": "s26fc26d"},
    {"name": "bsda_list_path", "value": bsda_list_path},
    {"name": "COLLECT_ENV", "value": "airflow"},
    {"name": "ingestion_time", "value": "230000"}
]
```

#### c) Cloud Run Job ì‹¤í–‰

```python
job = run_job(
    project="hyperlounge-dev",
    location="asia-northeast3",
    job_name="crawler",
    env_vars=env_vars,
    tasks=1,  # ìƒì„±í•  ì»¨í…Œì´ë„ˆ ê°œìˆ˜
    task_timeout="36000s"  # 10ì‹œê°„
)
```

**ì—­í• **: Cloud Run Job APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì‘ì—… ì‹¤í–‰

---

### 5ï¸âƒ£ Cloud Run Job Container ì‹œì‘

**íŒŒì¼**: `collector/deploy/run_crawler_job/Dockerfile`

```dockerfile
FROM python:3.8
WORKDIR /app

COPY app .
COPY main.py .
COPY requirements.txt .
COPY install_chrome.sh /app/install_chrome.sh

# Chrome ë° ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update
RUN apt-get install -y gconf-service libasound2 libatk1.0-0 ...
RUN /app/install_chrome.sh

# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN pip install --upgrade pip
RUN pip install --no-cache-dir -r requirements.txt

CMD ["python", "main.py"]
```

**ì—­í• **:
- Python 3.8 í™˜ê²½ êµ¬ì„±
- Chrome/ChromeDriver ì„¤ì¹˜ (ì…€ë ˆë‹ˆì›€ í¬ë¡¤ë§ìš©)
- í•„ìš”í•œ Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
- `main.py` ì‹¤í–‰

---

### 6ï¸âƒ£ Job Containerì—ì„œ main.py ì‹¤í–‰

**íŒŒì¼**: `collector/deploy/run_crawler_job/main.py`

#### a) í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

```python
# Google Cloud Runì´ ìë™ìœ¼ë¡œ ì£¼ì…í•˜ëŠ” í™˜ê²½ë³€ìˆ˜
TASK_INDEX = int(os.getenv("CLOUD_RUN_TASK_INDEX", 0))   # 0, 1, 2, ...
TASK_ATTEMPT = int(os.getenv("CLOUD_RUN_TASK_ATTEMPT", 3))
TASK_COUNT = int(os.getenv("CLOUD_RUN_TASK_COUNT", 1))

# Airflowì—ì„œ ì „ë‹¬í•œ í™˜ê²½ë³€ìˆ˜
customer_code = os.getenv("customer_code")      # "c230c700"
source_type = os.getenv("source_type")          # "board"
source_id = os.getenv("source_id")              # "s26fc26d"
ingestion_time = os.getenv("ingestion_time")    # "230000"
bsda_list_path = os.getenv("bsda_list_path")
```

#### b) BSDA ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ë° ì‘ì—… ë²”ìœ„ ê²°ì •

```python
bsda_list = get_from_gcs(
    bucket_name="hyperlounge-collect-config",
    source_blob_name=bsda_list_path,
    is_json=True
)
# bsda_list = [{"start": "2025-12-02", "end": "2025-12-02"}]

# ğŸ”‘ í•µì‹¬: TASK_INDEXë¡œ ìê¸° ë‹´ë‹¹ ë²”ìœ„ë§Œ ê°€ì ¸ì˜´
start_bsda = bsda_list[TASK_INDEX]["start"]  # "2025-12-02"
end_bsda = bsda_list[TASK_INDEX]["end"]      # "2025-12-02"
```

#### c) í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

```python
# ingestion_id ìƒì„±
ingestion_id = start_bsda.replace("-", "") + ingestion_time
ingestion_datetime = datetime.strptime(ingestion_id, "%Y%m%d%H%M%S")

# Firestoreì—ì„œ í¬ë¡¤ ì•¡ì…˜ ê°€ì ¸ì˜¤ê¸°
crawl_actions = get_task_items(
    api_svr_url, customer_code, source_type,
    TASK_CRAWL, ingestion_id, source_id
)["sources"][0]["crawl_actions"]

# í¬ë¡¤ëŸ¬ ìƒì„± (ì˜ˆ: WonikqncBoardCrawler)
crawler = get_crawler(
    project_id, customer_code, source_id,
    sync_bucket_name, sync_path,
    ingestion_datetime, ingestion_datetime,
    crawler_name="wonikqnc"
)
```

#### d) API ë¡œê·¸ì¸ ë° í¬ë¡¤ë§ ì‹¤í–‰

```python
# Secret Managerì—ì„œ API Key ê°€ì ¸ì˜¤ê¸°
crawler.get_api_key(login_by_req_info)

# ì‹¤ì œ í¬ë¡¤ë§ ìˆ˜í–‰
crawler.target_crawling(crawl_actions)

# ì—ëŸ¬ ì²˜ë¦¬
if crawler.error_result:
    crawler.upload_error_result()
```

---

### 7ï¸âƒ£ WonikqncBoardCrawler ì‹¤í–‰

**íŒŒì¼**: `collector/boards/api/wonikqnc_api_crawler.py:60-146`

```python
def crawl(self, crawl_action):
    # 1. íŒŒì¼ëª… ìƒì„±
    file_name = self.generate_file_name(date_list, FOLDER_CODE, DATE_RANGE, INF_ID, PARAM1)
    # ì˜ˆ: "20251202_20251202-20251202_D_lq10_ê¸ˆì¼_DW_DWH_001_LABOR_COST.xlsx"

    # 2. API ìš”ì²­ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    max_retries = 3
    for attempt in range(max_retries):
        res = requests.post(self.base_url, json=body, headers=headers, timeout=180)
        if res.status_code == 200:
            break
        if res.status_code == 504:  # Gateway Timeout
            time.sleep(10)
            continue

    # 3. ì‘ë‹µ ì²˜ë¦¬
    http_res = res.json()['HTTP_RESPONSE']
    data_cnt = http_res['DATA_COUNT']

    if data_cnt == 0:
        # ğŸ†• ë¹ˆ ì—‘ì…€ íŒŒì¼ ìƒì„± (ìˆ˜ì • ì‚¬í•­)
        df = DataFrame()
        excel_path = f"{self.abspath}/{file_name}"
        make_excel(df=df, excel_path=excel_path)
        ob_meta = self.get_metadata(file_name=file_name)
        self.upload(ob_meta, src_path=excel_path)
        return

    # 4. ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° Excel ì €ì¥
    data_list = http_res[INF_ID]
    df = self.make_df(data_list)
    excel_path = f"{self.abspath}/{file_name}"
    make_excel(df=df, excel_path=excel_path)

    # 5. GCS ì—…ë¡œë“œ
    ob_meta = self.get_metadata(file_name=file_name)
    self.upload(ob_meta, src_path=excel_path)
    # ì—…ë¡œë“œ ìœ„ì¹˜: gs://hyperlounge-c230c700-foldersync/board/s26fc26d/20251202230000/
```

---

### 8ï¸âƒ£ Airflowë¡œ ê²°ê³¼ ë°˜í™˜

```python
# main_board_crawler.py:261-264
check_run_job_execution_state(
    project=PROJECT_NAME,
    location=DEFAULT_ZONE,
    job_name="crawler",
    execution_id=execution_id
)

check_run_job_execution_tasks_state(
    project=PROJECT_NAME,
    location=DEFAULT_ZONE,
    job_name="crawler",
    execution_id=execution_id,
    retry_num=retry_num,
    sleep_time=sleep_time
)
```

**ì—­í• **:
- Job ì‹¤í–‰ ìƒíƒœ í´ë§
- ëª¨ë“  Task ì™„ë£Œ ëŒ€ê¸°
- ì„±ê³µ ì‹œ Airflow Task ì„±ê³µ â†’ ë‹¤ìŒ Task (fileid_mapping) ì‹¤í–‰

---

## ë³‘ë ¬ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜

### Cloud Run Jobì˜ taskCount ì„¤ì •

**íŒŒì¼**: `collector/common/run_job_util.py:240`

```python
body["overrides"] = {
    "taskCount": tasks,  # ì˜ˆ: tasks=10
    "timeout": task_timeout
}
```

**ê²°ê³¼**: ê°™ì€ Docker ì´ë¯¸ì§€ë¡œ Nê°œì˜ ë…ë¦½ëœ ì»¨í…Œì´ë„ˆê°€ ìƒì„±ë¨

---

### Google Cloud Runì´ ìë™ ì£¼ì…í•˜ëŠ” í™˜ê²½ë³€ìˆ˜

| í™˜ê²½ë³€ìˆ˜ | ì„¤ëª… | ì˜ˆì‹œ |
|---------|------|------|
| `CLOUD_RUN_TASK_INDEX` | í˜„ì¬ Taskì˜ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘) | 0, 1, 2, ..., 9 |
| `CLOUD_RUN_TASK_COUNT` | ì „ì²´ Task ê°œìˆ˜ | 10 |
| `CLOUD_RUN_TASK_ATTEMPT` | í˜„ì¬ ì¬ì‹œë„ íšŸìˆ˜ | 1, 2, 3 |
| `CLOUD_RUN_JOB` | Job ì´ë¦„ | crawler |
| `CLOUD_RUN_EXECUTION` | Execution ID | abc123def456 |

---

### ì‘ì—… ë¶„ë°° ë©”ì»¤ë‹ˆì¦˜

**íŒŒì¼**: `collector/deploy/run_crawler_job/main.py:68`

```python
# ê° ì»¨í…Œì´ë„ˆê°€ ìê¸° ë‹´ë‹¹ ì‘ì—…ë§Œ ê°€ì ¸ì˜´
start_bsda, end_bsda = bsda_list[TASK_INDEX]["start"], bsda_list[TASK_INDEX]["end"]
```

#### ì˜ˆì‹œ: 30ì¼ì¹˜ ë°ì´í„°ë¥¼ 10ê°œ Taskë¡œ ë¶„ë°°

**Airflowì—ì„œ BSDA ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„**:
```python
bsda_list = [
    {"start": "2025-12-01", "end": "2025-12-03"},  # TASK_INDEX=0
    {"start": "2025-12-04", "end": "2025-12-06"},  # TASK_INDEX=1
    {"start": "2025-12-07", "end": "2025-12-09"},  # TASK_INDEX=2
    {"start": "2025-12-10", "end": "2025-12-12"},  # TASK_INDEX=3
    {"start": "2025-12-13", "end": "2025-12-15"},  # TASK_INDEX=4
    {"start": "2025-12-16", "end": "2025-12-18"},  # TASK_INDEX=5
    {"start": "2025-12-19", "end": "2025-12-21"},  # TASK_INDEX=6
    {"start": "2025-12-22", "end": "2025-12-24"},  # TASK_INDEX=7
    {"start": "2025-12-25", "end": "2025-12-27"},  # TASK_INDEX=8
    {"start": "2025-12-28", "end": "2025-12-30"},  # TASK_INDEX=9
]
```

**Cloud Runì´ 10ê°œ ì»¨í…Œì´ë„ˆ ìƒì„±**:

| ì»¨í…Œì´ë„ˆ | TASK_INDEX | ë‹´ë‹¹ ë‚ ì§œ | CPU | Memory | ìƒíƒœ |
|----------|------------|-----------|-----|--------|------|
| Container-0 | 0 | 12/01~12/03 | 1 | 512Mi | Running |
| Container-1 | 1 | 12/04~12/06 | 1 | 512Mi | Running |
| Container-2 | 2 | 12/07~12/09 | 1 | 512Mi | Running |
| Container-3 | 3 | 12/10~12/12 | 1 | 512Mi | Running |
| Container-4 | 4 | 12/13~12/15 | 1 | 512Mi | Running |
| Container-5 | 5 | 12/16~12/18 | 1 | 512Mi | Running |
| Container-6 | 6 | 12/19~12/21 | 1 | 512Mi | Running |
| Container-7 | 7 | 12/22~12/24 | 1 | 512Mi | Running |
| Container-8 | 8 | 12/25~12/27 | 1 | 512Mi | Running |
| Container-9 | 9 | 12/28~12/30 | 1 | 512Mi | Running |

**ê° ì»¨í…Œì´ë„ˆì—ì„œ ì‹¤í–‰ë˜ëŠ” ì½”ë“œ**:

```python
# Container-0ì˜ main.py
TASK_INDEX = 0  # Googleì´ ìë™ ì£¼ì…
bsda_list = get_from_gcs(...)  # ì „ì²´ ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ
start_bsda = bsda_list[0]["start"]  # "2025-12-01"
end_bsda = bsda_list[0]["end"]      # "2025-12-03"
# â†’ 12/01, 12/02, 12/03 í¬ë¡¤ë§

# Container-1ì˜ main.py
TASK_INDEX = 1  # Googleì´ ìë™ ì£¼ì…
bsda_list = get_from_gcs(...)  # ë™ì¼í•œ GCS íŒŒì¼
start_bsda = bsda_list[1]["start"]  # "2025-12-04"
end_bsda = bsda_list[1]["end"]      # "2025-12-06"
# â†’ 12/04, 12/05, 12/06 í¬ë¡¤ë§
```

---

## ë©”ëª¨ë¦¬ ê´€ë¦¬ ì›ë¦¬

### ê° ì»¨í…Œì´ë„ˆëŠ” ì™„ì „íˆ ë…ë¦½

**íŒŒì¼**: `collector/common/run_job_util.py:70-86`

```python
"template": {
    "containers": [{
        "image": "asia-northeast3-docker.pkg.dev/hyperlounge-dev/cloud-run-job/crawler:latest",
        "resources": {
            "limits": {
                "cpu": "1",       # ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ 1 vCPU
                "memory": "512Mi" # ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ 512MB
            }
        }
    }]
}
```

### ë¦¬ì†ŒìŠ¤ ê²©ë¦¬

| í•­ëª© | ì„¤ëª… |
|------|------|
| **CPU** | ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ ë…ë¦½ëœ vCPU í• ë‹¹ |
| **ë©”ëª¨ë¦¬** | ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ ë…ë¦½ëœ ë©”ëª¨ë¦¬ ê³µê°„ (512Mi) |
| **ë””ìŠ¤í¬** | ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ ì„ì‹œ ë””ìŠ¤í¬ ê³µê°„ |
| **ë„¤íŠ¸ì›Œí¬** | ê° ì»¨í…Œì´ë„ˆê°€ ë…ë¦½ì ìœ¼ë¡œ API í˜¸ì¶œ |
| **Python í”„ë¡œì„¸ìŠ¤** | ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ ë³„ë„ Python ì¸í„°í”„ë¦¬í„° |

### ë©”ëª¨ë¦¬ ê³µìœ  ì—¬ë¶€

| êµ¬ë¶„ | ê³µìœ  ì—¬ë¶€ | ì„¤ëª… |
|------|-----------|------|
| **Docker ì´ë¯¸ì§€** | âœ… ê³µìœ  (ì½ê¸° ì „ìš©) | ëª¨ë“  ì»¨í…Œì´ë„ˆê°€ ê°™ì€ ì´ë¯¸ì§€ ì‚¬ìš© |
| **Python ì½”ë“œ** | âœ… ê³µìœ  (ì½ê¸° ì „ìš©) | ì´ë¯¸ì§€ì— í¬í•¨ëœ ì½”ë“œ |
| **í™ ë©”ëª¨ë¦¬** | âŒ ë…ë¦½ | ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ ë³„ë„ í• ë‹¹ |
| **ìŠ¤íƒ ë©”ëª¨ë¦¬** | âŒ ë…ë¦½ | ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ ë³„ë„ í• ë‹¹ |
| **ë³€ìˆ˜/ê°ì²´** | âŒ ë…ë¦½ | ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ ë…ë¦½ ìƒì„± |
| **GCS ë°ì´í„°** | âœ… ê³µìœ  | ê°™ì€ bsda_list íŒŒì¼ ì½ìŒ |

### ì‹¤í–‰ ë°©ì‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Docker Image (ì½ê¸° ì „ìš©)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Python 3.8, Chrome, ChromeDriver, main.py, ...     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“ (ë³µì œ)
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Container-0    â”‚  Container-1    â”‚  Container-2    â”‚
        â”‚  INDEX=0        â”‚  INDEX=1        â”‚  INDEX=2        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  Python í”„ë¡œì„¸ìŠ¤ â”‚  Python í”„ë¡œì„¸ìŠ¤ â”‚  Python í”„ë¡œì„¸ìŠ¤ â”‚
        â”‚  ë…ë¦½ ë©”ëª¨ë¦¬ 512Mâ”‚  ë…ë¦½ ë©”ëª¨ë¦¬ 512Mâ”‚  ë…ë¦½ ë©”ëª¨ë¦¬ 512Mâ”‚
        â”‚  CPU: 1 vCPU   â”‚  CPU: 1 vCPU   â”‚  CPU: 1 vCPU   â”‚
        â”‚  bsda[0] ì²˜ë¦¬   â”‚  bsda[1] ì²˜ë¦¬   â”‚  bsda[2] ì²˜ë¦¬   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ì‹¤í–‰ íë¦„ ë¹„êµ

### ë‹¨ì¼ Task (tasks=1)

```
Airflow Trigger
    â†“
bsda_list = [{"start": "2025-12-02", "end": "2025-12-02"}]
    â†“
Cloud Run Job ì‹œì‘ (taskCount=1)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Container-0                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ TASK_INDEX = 0                     â”‚ â”‚
â”‚  â”‚ start_bsda = "2025-12-02"         â”‚ â”‚
â”‚  â”‚ end_bsda = "2025-12-02"           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                          â”‚
â”‚  WonikqncBoardCrawler ì‹¤í–‰               â”‚
â”‚  â”œâ”€ API í˜¸ì¶œ 1: LABOR_COST              â”‚
â”‚  â”œâ”€ API í˜¸ì¶œ 2: PRODUCTIVITY            â”‚
â”‚  â”œâ”€ API í˜¸ì¶œ 3: SO_AMT_CURM             â”‚
â”‚  â””â”€ ...                                 â”‚
â”‚                                          â”‚
â”‚  ê²°ê³¼: 19ê°œ íŒŒì¼ ìƒì„±                     â”‚
â”‚  GCS ì—…ë¡œë“œ ì™„ë£Œ                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Job ì™„ë£Œ
    â†“
Airflow Task ì„±ê³µ
```

**íŠ¹ì§•**:
- ìˆœì°¨ ì²˜ë¦¬
- ë‹¨ì¼ ì»¨í…Œì´ë„ˆ
- ì‹¤í–‰ ì‹œê°„: ~10ë¶„

---

### ë³‘ë ¬ Task (tasks=10)

```
Airflow Trigger
    â†“
bsda_list = [
    {"start": "2025-12-01", "end": "2025-12-03"},
    {"start": "2025-12-04", "end": "2025-12-06"},
    ...
]
    â†“
Cloud Run Job ì‹œì‘ (taskCount=10)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Container-0  â”‚ Container-1  â”‚ Container-2  â”‚ ... â”‚ Container-9  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INDEX=0      â”‚ INDEX=1      â”‚ INDEX=2      â”‚     â”‚ INDEX=9      â”‚
â”‚ 12/01~03     â”‚ 12/04~06     â”‚ 12/07~09     â”‚     â”‚ 12/28~30     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Crawler ì‹¤í–‰  â”‚ Crawler ì‹¤í–‰  â”‚ Crawler ì‹¤í–‰  â”‚     â”‚ Crawler ì‹¤í–‰  â”‚
â”‚ 19 files x3  â”‚ 19 files x3  â”‚ 19 files x3  â”‚     â”‚ 19 files x3  â”‚
â”‚ = 57 files   â”‚ = 57 files   â”‚ = 57 files   â”‚     â”‚ = 57 files   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“              â†“              â†“        ...        â†“
    GCS ì—…ë¡œë“œ     GCS ì—…ë¡œë“œ     GCS ì—…ë¡œë“œ           GCS ì—…ë¡œë“œ
        â†“              â†“              â†“        ...        â†“
                    ëª¨ë“  ì»¨í…Œì´ë„ˆ ì™„ë£Œ ëŒ€ê¸°
                            â†“
                       Job ì™„ë£Œ
                            â†“
                    Airflow Task ì„±ê³µ
```

**íŠ¹ì§•**:
- ë³‘ë ¬ ì²˜ë¦¬ (ë™ì‹œ ì‹¤í–‰)
- 10ê°œ ì»¨í…Œì´ë„ˆ
- ì‹¤í–‰ ì‹œê°„: ~10ë¶„ (ë‹¨ì¼ Taskì™€ ìœ ì‚¬í•˜ì§€ë§Œ 30ì¼ì¹˜ ì²˜ë¦¬)
- ì´ 570ê°œ íŒŒì¼ ìƒì„±

---

## í•µì‹¬ ì •ë¦¬

### ì•„í‚¤í…ì²˜ íŠ¹ì§•

| í•­ëª© | ì„¤ëª… |
|------|------|
| **ì½”ë“œ ê³µìœ ** | âœ… ëª¨ë“  ì»¨í…Œì´ë„ˆê°€ ê°™ì€ Docker ì´ë¯¸ì§€ ì‚¬ìš© |
| **ë©”ëª¨ë¦¬ ê³µìœ ** | âŒ ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ ë…ë¦½ëœ ë©”ëª¨ë¦¬ ê³µê°„ |
| **í”„ë¡œì„¸ìŠ¤** | ê° ì»¨í…Œì´ë„ˆë§ˆë‹¤ ë³„ë„ Python í”„ë¡œì„¸ìŠ¤ |
| **ì‘ì—… ë¶„ë°°** | `TASK_INDEX` í™˜ê²½ë³€ìˆ˜ë¡œ ìë™ ë¶„ë°° |
| **ì‹¤í–‰ ë°©ì‹** | ë³‘ë ¬ (ë™ì‹œì— Nê°œ ì‹¤í–‰) |
| **ê²©ë¦¬ì„±** | í•œ ì»¨í…Œì´ë„ˆ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆëŠ” ê³„ì† ì‹¤í–‰ |
| **ë¹„ìš©** | ì»¨í…Œì´ë„ˆë‹¹ ë…ë¦½ ì²­êµ¬ (ì‹¤í–‰ ì‹œê°„ Ã— CPU/ë©”ëª¨ë¦¬) |

---

### Airflow Worker vs Cloud Run Job

| ê¸°ëŠ¥ | Airflow Worker | Cloud Run Job |
|------|---------------|---------------|
| **ì‹¤í–‰ ì‹œê°„ ì œí•œ** | ì œí•œì  (ìˆ˜ ì‹œê°„) | ìµœëŒ€ 24ì‹œê°„ |
| **ë¦¬ì†ŒìŠ¤** | ê³µìœ  ë¦¬ì†ŒìŠ¤ (ë‹¤ë¥¸ Taskì™€ ê²½í•©) | ë…ë¦½ ë¦¬ì†ŒìŠ¤ (ê²©ë¦¬) |
| **ë³‘ë ¬ ì²˜ë¦¬** | Worker ìˆ˜ë§Œí¼ ì œí•œ | ë¬´ì œí•œ (taskCount ì¡°ì •) |
| **ë³µì¡í•œ ì˜ì¡´ì„±** | ì„¤ì¹˜ ì–´ë ¤ì›€ | Dockerfileë¡œ ììœ ë¡­ê²Œ |
| **Chrome/Selenium** | Workerì— ì„¤ì¹˜ ë³µì¡ | Dockerfileë¡œ ê°„ë‹¨íˆ ì„¤ì¹˜ |
| **í™•ì¥ì„±** | Worker ì¶”ê°€ í•„ìš” | taskCountë§Œ ì¦ê°€ |
| **ë¹„ìš©** | Worker ê³ ì • ë¹„ìš© | ì‚¬ìš©í•œ ë§Œí¼ ì²­êµ¬ |

---

### ì–¸ì œ ë³‘ë ¬í™”ë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?

#### âœ… ë³‘ë ¬í™”ê°€ í•„ìš”í•œ ê²½ìš°

1. **ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘**
   - ìˆ˜ë°± ê°œ íŒŒì¼ í¬ë¡¤ë§
   - ì—¬ëŸ¬ ë‹¬ì¹˜ íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘

2. **ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…**
   - ê° ì‘ì—…ì´ 10ë¶„ ì´ìƒ
   - API í˜¸ì¶œì´ ëŠë¦° ê²½ìš°

3. **RPA í¬ë¡¤ë§**
   - ì—¬ëŸ¬ ê³„ì •ìœ¼ë¡œ ë™ì‹œ ë¡œê·¸ì¸
   - ì˜ˆ: `guest_num=5`ë¡œ 5ê°œ ë³‘ë ¬ ì‹¤í–‰

#### âŒ ë³‘ë ¬í™”ê°€ ë¶ˆí•„ìš”í•œ ê²½ìš°

1. **ì›ìµíì—”ì”¨ (í˜„ì¬)**
   - í•˜ë£¨ì¹˜ ë°ì´í„°ë§Œ í¬ë¡¤ë§ (19ê°œ íŒŒì¼)
   - API í˜¸ì¶œì´ ë¹ ë¦„ (ì „ì²´ 10ë¶„ ì´ë‚´)
   - `tasks=1`ë¡œ ì¶©ë¶„

2. **API Rate Limitì´ ìˆëŠ” ê²½ìš°**
   - ë³‘ë ¬ ìš”ì²­ì´ ì œí•œë  ìˆ˜ ìˆìŒ
   - ìˆœì°¨ ì²˜ë¦¬ê°€ ë” ì•ˆì „

---

### ë³‘ë ¬í™” ì„¤ì • ì˜ˆì‹œ

#### ì˜ˆì‹œ 1: 1ê°œì›” íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ (tasks=10)

```python
# Airflow DAGì—ì„œ
bsda_list = []
for i in range(10):
    start = "2025-11-01" + timedelta(days=i*3)
    end = "2025-11-01" + timedelta(days=(i+1)*3-1)
    bsda_list.append({"start": start.strftime("%Y-%m-%d"),
                      "end": end.strftime("%Y-%m-%d")})

# Cloud Run Job ì‹¤í–‰
board_crawler_with_job(..., tasks=10)
```

#### ì˜ˆì‹œ 2: RPA ë³‘ë ¬ í¬ë¡¤ë§ (tasks=5)

```python
# c230c700.pyì˜ RPA ì„¤ì •
source_confs = [
    {
        "source": "rpa",
        "enable": True,
    }
]

# DAGì—ì„œ ìë™ìœ¼ë¡œ guest_numë§Œí¼ Task ìƒì„±
guest_num = 5  # 5ê°œ Guest VM
for task_num in range(guest_num):
    crawler_task = RPATasks.generate_rpa_crawler_task(
        CONFIG, source_id, source, task_num
    )
```

---

### ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

#### ë¬¸ì œ 1: Taskê°€ Timeout

**ì¦ìƒ**: Jobì´ `task_timeout`ì„ ì´ˆê³¼í•˜ì—¬ ì‹¤íŒ¨

**í•´ê²°**:
```python
# task_timeout ì¦ê°€
board_crawler_with_job(..., task_timeout="72000s")  # 20ì‹œê°„
```

#### ë¬¸ì œ 2: Memory ë¶€ì¡±

**ì¦ìƒ**: Containerê°€ OOM (Out of Memory)ìœ¼ë¡œ ì‹¤íŒ¨

**í•´ê²°**:
```python
# Job ìƒì„± ì‹œ ë©”ëª¨ë¦¬ ì¦ê°€
create_run_job(..., memory="1Gi")  # 512Mi â†’ 1Gi
```

#### ë¬¸ì œ 3: ì¼ë¶€ Taskë§Œ ì‹¤íŒ¨

**ì¦ìƒ**: 10ê°œ ì¤‘ 2ê°œ Taskê°€ ì‹¤íŒ¨

**ì¥ì **: ë‚˜ë¨¸ì§€ 8ê°œëŠ” ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
**í•´ê²°**: ì‹¤íŒ¨í•œ Taskì˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ê°œë³„ ìˆ˜ì •

```bash
# Cloud Run Job Execution ë¡œê·¸ í™•ì¸
gcloud logging read "resource.type=cloud_run_job AND \
  resource.labels.job_name=crawler AND \
  resource.labels.location=asia-northeast3" \
  --limit 100 --format json
```

---

### ëª¨ë‹ˆí„°ë§

#### Cloud Consoleì—ì„œ í™•ì¸

```
https://console.cloud.google.com/run/jobs/executions/details/{location}/{execution_id}/tasks?project={project}
```

#### ë¡œê·¸ í™•ì¸

```python
# main_board_crawler.py:221-222
logger.info(f"job_name={job_name}, execution_id={execution_id}, env_vars={env_vars}, "
            f"task_timeout={task_timeout}")
```

#### Task ìƒíƒœ í™•ì¸

```python
# run_job_util.py:399-433
def check_run_job_execution_tasks_state(...):
    tasks = list_run_job_execution_tasks(...)

    success_tasks_count = task_statuses.count(TaskCondition.SUCCEEDED)
    fail_tasks_count = task_statuses.count(TaskCondition.FAILED)

    logger.info(
        f"total_tasks_count={total_tasks_count}, "
        f"success_tasks_count={success_tasks_count}, "
        f"fail_tasks_count={fail_tasks_count}"
    )
```

---

## ì°¸ê³  ìë£Œ

### ì£¼ìš” íŒŒì¼ ìœ„ì¹˜

| íŒŒì¼ | ì—­í•  |
|------|------|
| `airflow-dags/dags/c230c700.py` | ì›ìµíì—”ì”¨ DAG ì •ì˜ |
| `airflow-dags/dags/dependencies/task_factory.py` | Task ìƒì„± íŒ©í† ë¦¬ |
| `airflow-dags/dags/dependencies/task_functions.py` | Task ì‹¤í–‰ í•¨ìˆ˜ |
| `collector/cloud/file_crawler.py` | í¬ë¡¤ëŸ¬ ì§„ì…ì  |
| `collector/boards/main_board_crawler.py` | Cloud Run Job ì‹¤í–‰ |
| `collector/common/run_job_util.py` | Cloud Run Job API í˜¸ì¶œ |
| `collector/deploy/run_crawler_job/main.py` | Job Container ì‹¤í–‰ ì½”ë“œ |
| `collector/deploy/run_crawler_job/Dockerfile` | Container ì´ë¯¸ì§€ ì •ì˜ |
| `collector/boards/api/wonikqnc_api_crawler.py` | ì›ìµíì—”ì”¨ í¬ë¡¤ëŸ¬ êµ¬í˜„ |

### Cloud Run Job ê³µì‹ ë¬¸ì„œ

- [Cloud Run Jobs Overview](https://cloud.google.com/run/docs/create-jobs)
- [Container Contract](https://cloud.google.com/run/docs/container-contract?hl=ko#jobs-env-vars)
- [REST API Reference](https://cloud.google.com/run/docs/reference/rest/v2/projects.locations.jobs)

---

## ë³€ê²½ ì´ë ¥

| ë‚ ì§œ | ì‘ì„±ì | ë‚´ìš© |
|------|--------|------|
| 2025-12-03 | Claude | ì´ˆì•ˆ ì‘ì„± |
| 2025-12-03 | Claude | ì›ìµíì—”ì”¨ ë¹ˆ íŒŒì¼ ì²˜ë¦¬ ì¶”ê°€ |

---

**ë¬¸ì„œ ì‘ì„±ì¼**: 2025-12-03
**ìµœì¢… ìˆ˜ì •ì¼**: 2025-12-03
**ë²„ì „**: 1.0
